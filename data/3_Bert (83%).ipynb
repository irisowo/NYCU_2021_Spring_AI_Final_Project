{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_Bert.ipynb","provenance":[],"collapsed_sections":["sNhdyYEMKuJP","zyXbAI2Il9mk","Q8Lv419xbc5I","aKx8H4YYMNah","hQNfO85-v8cb"]},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"accelerator":"GPU","kernel_info":{"name":"python3"},"language_info":{"name":"python","version":"3.7.0","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"nteract":{"version":"0.12.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"33fcf1ed720d441a8635f0453d3b40c3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a8c0288a16614fb68f79476a0fa3924c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_489113c32c0b432e886fe11d8e3cdab1","IPY_MODEL_5a56e9f8c28f47afb5081fdf81f160db"]}},"a8c0288a16614fb68f79476a0fa3924c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"489113c32c0b432e886fe11d8e3cdab1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c0ebd7bc77f94605ad67045efa2eb254","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":109540,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":109540,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_59cbefb4947141aca6b05285c200cf0c"}},"5a56e9f8c28f47afb5081fdf81f160db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fe78929dc360464ba600e168356be542","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 110k/110k [00:00&lt;00:00, 220kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_75b35ac66b93498ebd90e72104036bf3"}},"c0ebd7bc77f94605ad67045efa2eb254":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"59cbefb4947141aca6b05285c200cf0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fe78929dc360464ba600e168356be542":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"75b35ac66b93498ebd90e72104036bf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1434415d4c054936a1a6428ad0de935f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c055207170464d06be06c6a8bbb56455","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3a5654046c814e15a9d57b6f7ae51314","IPY_MODEL_c80ec20d34f8475bb0f8f61a949d8b64"]}},"c055207170464d06be06c6a8bbb56455":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3a5654046c814e15a9d57b6f7ae51314":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d75e22a5733f4659ac8c1b4c4adb5e82","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1460e1d82cca4fe1a486f38818d6924d"}},"c80ec20d34f8475bb0f8f61a949d8b64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6bacc791df3a42e7930481f40f75e431","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.00/2.00 [00:00&lt;00:00, 9.64B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b034d136dec146b7ba1ff89ceba24448"}},"d75e22a5733f4659ac8c1b4c4adb5e82":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1460e1d82cca4fe1a486f38818d6924d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6bacc791df3a42e7930481f40f75e431":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b034d136dec146b7ba1ff89ceba24448":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d69fb70e87684aa3afc6a083d63402de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_73f0627ba6d14874becdb2679fb30b4a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_97747eb7f8884451aed5397c7f76a8b4","IPY_MODEL_e10a95246ccf4c449e28a36bab0a5410"]}},"73f0627ba6d14874becdb2679fb30b4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"97747eb7f8884451aed5397c7f76a8b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_792fb1ddcd4248c2ad1c3e399224575e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":112,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":112,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9fddd8b7ff2a4da7a802f76cdb272630"}},"e10a95246ccf4c449e28a36bab0a5410":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f5a0502ee77a4059a80b2eff763e12d8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 112/112 [00:00&lt;00:00, 1.01kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f1f4de3342d34fca9aa30161fdb83edf"}},"792fb1ddcd4248c2ad1c3e399224575e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9fddd8b7ff2a4da7a802f76cdb272630":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f5a0502ee77a4059a80b2eff763e12d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f1f4de3342d34fca9aa30161fdb83edf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"49ff70fb53fc48ed90fdcf0705ea912e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ab52ae84f9f34550930fcb4cd3ab4684","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_11375549faaf4955af1fb4bbd2ee5787","IPY_MODEL_eab82b1d388c44aca7454648bcc38387"]}},"ab52ae84f9f34550930fcb4cd3ab4684":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"11375549faaf4955af1fb4bbd2ee5787":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a32b6f3c6158429c969475725094b756","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":19,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":19,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4e6f1e0bdd6d44bfbb3dc6d8bccc7d98"}},"eab82b1d388c44aca7454648bcc38387":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2b58f6ff5178408d97772788ab445c37","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 19.0/19.0 [00:00&lt;00:00, 99.4B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9fa38db106d6456fb605f35501135b3a"}},"a32b6f3c6158429c969475725094b756":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4e6f1e0bdd6d44bfbb3dc6d8bccc7d98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2b58f6ff5178408d97772788ab445c37":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9fa38db106d6456fb605f35501135b3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8fe76ff0ca664cfa94787ce3cd37257c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a4b1546ce3554d80a459fa4520dbe9c3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f700aa88ce0f4f8c91e9d9b18114be29","IPY_MODEL_60645535f0b643b5b95e78d40ee231b3"]}},"a4b1546ce3554d80a459fa4520dbe9c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f700aa88ce0f4f8c91e9d9b18114be29":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_87db87a067324c2db3360e9532ab388b","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":268961,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":268961,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1dc17037e554451ca351fec9fb20d8ee"}},"60645535f0b643b5b95e78d40ee231b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_374fd39c6eec44ba9adc1a08829f1372","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 269k/269k [00:00&lt;00:00, 3.23MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_310d48f32ab74d0aa757f92ca685799a"}},"87db87a067324c2db3360e9532ab388b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1dc17037e554451ca351fec9fb20d8ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"374fd39c6eec44ba9adc1a08829f1372":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"310d48f32ab74d0aa757f92ca685799a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8b993d50d46045c9ab588a90502ac374":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5ae7f27015244d0ca08b016630807738","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b4879e44ec224437927b2504ca63c322","IPY_MODEL_43c89feb256e4da3b30d51116e0e6b5e"]}},"5ae7f27015244d0ca08b016630807738":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b4879e44ec224437927b2504ca63c322":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0fc86d80fad8449eb890467648b0a2e5","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":647,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":647,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2a37b2869688432981e6fcbbfd69eee5"}},"43c89feb256e4da3b30d51116e0e6b5e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1731608e6a53496ab1cb1b5aeb0ed3fb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 647/647 [00:10&lt;00:00, 60.8B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_59545af6017945dc99e0f421bdfbfcdc"}},"0fc86d80fad8449eb890467648b0a2e5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2a37b2869688432981e6fcbbfd69eee5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1731608e6a53496ab1cb1b5aeb0ed3fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"59545af6017945dc99e0f421bdfbfcdc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"04074b5d1f2d45999d4347b6da8252ad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bdb60a8577c04a5b8467b3614db06ce3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_555142f6bb904231a2cfe4214e83f25f","IPY_MODEL_e5895dc00516429f8e337a806a2cf301"]}},"bdb60a8577c04a5b8467b3614db06ce3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"555142f6bb904231a2cfe4214e83f25f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a28e070e4c6f4e9db84fd8a30acdea76","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":411578458,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":411578458,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d5948cf9f11d453aa4677cc06dab4255"}},"e5895dc00516429f8e337a806a2cf301":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d19956dad055498b872ab0352ab97497","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 412M/412M [00:10&lt;00:00, 39.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ffc09015e2f248b5ae99eef70e9c228c"}},"a28e070e4c6f4e9db84fd8a30acdea76":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d5948cf9f11d453aa4677cc06dab4255":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d19956dad055498b872ab0352ab97497":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ffc09015e2f248b5ae99eef70e9c228c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"sNhdyYEMKuJP"},"source":["#Part 1 處理 train data\n","train/test來源 ：https://github.com/wshuyi/demo-chinese-text-classification-lstm-keras/blob/master/demo.ipynb\n","\n","code 來源 ：https://blog.csdn.net/Jerryzhangjy/article/details/110209984"]},{"cell_type":"markdown","metadata":{"id":"muOg73EpM_GG"},"source":["##1.1 import"]},{"cell_type":"code","metadata":{"id":"68JkPB8NbKzX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624526570524,"user_tz":-480,"elapsed":4024,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"2e67bfdc-3f13-4c64-aade-f046a877bf39"},"source":["!pip install keras.utils\n","import pandas as pd\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting keras.utils\n","  Downloading https://files.pythonhosted.org/packages/31/a2/8be2aee1c8cd388e83d447556c2c84a396944c8bad93d710c5e757f8e98e/keras-utils-1.0.13.tar.gz\n","Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.7/dist-packages (from keras.utils) (2.4.3)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras.utils) (1.19.5)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras.utils) (1.4.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras.utils) (3.1.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras.utils) (3.13)\n","Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->Keras>=2.1.5->keras.utils) (1.5.2)\n","Building wheels for collected packages: keras.utils\n","  Building wheel for keras.utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras.utils: filename=keras_utils-1.0.13-cp37-none-any.whl size=2657 sha256=e161b9a98c31794e9dff3c611abed96ea96f1c00f4c010edd56b01be86e3875d\n","  Stored in directory: /root/.cache/pip/wheels/46/25/27/7707005c1cb27e1ffc8277b004ac295e34767b02b44d73d6be\n","Successfully built keras.utils\n","Installing collected packages: keras.utils\n","Successfully installed keras.utils\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DFRr_P18Mfv2","executionInfo":{"status":"ok","timestamp":1624526580944,"user_tz":-480,"elapsed":10424,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"64ec1c1f-a605-4029-e8ae-1e323fd3919b"},"source":["! pip3 install transformers\n","! pip3 install keras\n","! pip3 install tensorflow"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/f7/9287c330b0a195f67b6ce92f471c94084cdec1f596eb13b374704831f15a/transformers-4.8.0-py3-none-any.whl (2.5MB)\n","\u001b[K     |████████████████████████████████| 2.5MB 27.2MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 39.2MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting huggingface-hub==0.0.12\n","  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 39.7MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Installing collected packages: sacremoses, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.0\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (3.1.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n","Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.5.2)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.5.0)\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0.dev2021032900)\n","Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n","Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.34.1)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.31.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (57.0.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (2.23.0)\n","Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.4.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q_jYaxZuMrPJ","executionInfo":{"status":"ok","timestamp":1624526584800,"user_tz":-480,"elapsed":3858,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"4735a987-8037-4b12-d9f3-561b0d4b2cec"},"source":["import torch\n","if torch.cuda.is_available():    \n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zyXbAI2Il9mk"},"source":["##1.2 讀檔"]},{"cell_type":"code","metadata":{"id":"md4Mf2P8CKKb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624526587711,"user_tz":-480,"elapsed":2924,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"c1a023a0-e025-4b7e-e58b-d70619abda44"},"source":["!git clone https://github.com/wshuyi/demo-chinese-text-classification-lstm-keras.git"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Cloning into 'demo-chinese-text-classification-lstm-keras'...\n","remote: Enumerating objects: 16, done.\u001b[K\n","remote: Total 16 (delta 0), reused 0 (delta 0), pack-reused 16\u001b[K\n","Unpacking objects: 100% (16/16), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qWfsKVfeCZmz","executionInfo":{"status":"ok","timestamp":1624526587711,"user_tz":-480,"elapsed":9,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}}},"source":["from pathlib import Path\n","mypath = Path(\"demo-chinese-text-classification-lstm-keras\")"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"ENeThW2vkeEp","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1624526587712,"user_tz":-480,"elapsed":9,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"4e0781e4-1cc1-433a-f073-f8b6f2caf7a3"},"source":["#-------------Modify the train_path----------------\n","\n","train_path = mypath/'dianping.csv'\n","\n","#-----------------------------------\n","df = pd.read_csv(train_path)\n","df.head(3)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>口味：不知道是我口高了，还是这家真不怎么样。 我感觉口味确实很一般很一般。上菜相当快，我敢说...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>菜品丰富质量好，服务也不错！很喜欢！</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>说真的，不晓得有人排队的理由，香精香精香精香精，拜拜！</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             comment  sentiment\n","0  口味：不知道是我口高了，还是这家真不怎么样。 我感觉口味确实很一般很一般。上菜相当快，我敢说...          0\n","1                                 菜品丰富质量好，服务也不错！很喜欢！          1\n","2                        说真的，不晓得有人排队的理由，香精香精香精香精，拜拜！          0"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"AP6cfTmqNdTX"},"source":["#Part 2 Bert"]},{"cell_type":"code","metadata":{"id":"12-W8Re7NfwP","executionInfo":{"status":"ok","timestamp":1624526587712,"user_tz":-480,"elapsed":6,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}}},"source":["import numpy as np\n","import pandas as pd\n","T_sentences = df.comment.values # T means Total\n","T_labels = np.array(df.sentiment.values,dtype=np.int32)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":274,"referenced_widgets":["33fcf1ed720d441a8635f0453d3b40c3","a8c0288a16614fb68f79476a0fa3924c","489113c32c0b432e886fe11d8e3cdab1","5a56e9f8c28f47afb5081fdf81f160db","c0ebd7bc77f94605ad67045efa2eb254","59cbefb4947141aca6b05285c200cf0c","fe78929dc360464ba600e168356be542","75b35ac66b93498ebd90e72104036bf3","1434415d4c054936a1a6428ad0de935f","c055207170464d06be06c6a8bbb56455","3a5654046c814e15a9d57b6f7ae51314","c80ec20d34f8475bb0f8f61a949d8b64","d75e22a5733f4659ac8c1b4c4adb5e82","1460e1d82cca4fe1a486f38818d6924d","6bacc791df3a42e7930481f40f75e431","b034d136dec146b7ba1ff89ceba24448","d69fb70e87684aa3afc6a083d63402de","73f0627ba6d14874becdb2679fb30b4a","97747eb7f8884451aed5397c7f76a8b4","e10a95246ccf4c449e28a36bab0a5410","792fb1ddcd4248c2ad1c3e399224575e","9fddd8b7ff2a4da7a802f76cdb272630","f5a0502ee77a4059a80b2eff763e12d8","f1f4de3342d34fca9aa30161fdb83edf","49ff70fb53fc48ed90fdcf0705ea912e","ab52ae84f9f34550930fcb4cd3ab4684","11375549faaf4955af1fb4bbd2ee5787","eab82b1d388c44aca7454648bcc38387","a32b6f3c6158429c969475725094b756","4e6f1e0bdd6d44bfbb3dc6d8bccc7d98","2b58f6ff5178408d97772788ab445c37","9fa38db106d6456fb605f35501135b3a","8fe76ff0ca664cfa94787ce3cd37257c","a4b1546ce3554d80a459fa4520dbe9c3","f700aa88ce0f4f8c91e9d9b18114be29","60645535f0b643b5b95e78d40ee231b3","87db87a067324c2db3360e9532ab388b","1dc17037e554451ca351fec9fb20d8ee","374fd39c6eec44ba9adc1a08829f1372","310d48f32ab74d0aa757f92ca685799a"]},"id":"HJPPN_UvNf6S","executionInfo":{"status":"ok","timestamp":1624526589139,"user_tz":-480,"elapsed":1432,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"aa013800-f3b0-4522-8407-c726ca0db338"},"source":["from transformers import BertTokenizer\n","from transformers import AutoTokenizer, AutoModelForMaskedLM\n","# Load the BERT tokenizer.\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained(\"hfl/chinese-bert-wwm-ext\")\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Loading BERT tokenizer...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"33fcf1ed720d441a8635f0453d3b40c3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=109540.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1434415d4c054936a1a6428ad0de935f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d69fb70e87684aa3afc6a083d63402de","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49ff70fb53fc48ed90fdcf0705ea912e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=19.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8fe76ff0ca664cfa94787ce3cd37257c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=268961.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Q8Lv419xbc5I"},"source":["## 2.1 preprocess of training data"]},{"cell_type":"code","metadata":{"id":"_DY3DUcBXhm1","executionInfo":{"status":"ok","timestamp":1624526589139,"user_tz":-480,"elapsed":4,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}}},"source":["LS = len(T_sentences)\n","training_samples = (int)(LS * 0.9)\n","sentences = T_sentences #[:training_samples]\n","labels = T_labels #[:training_samples]\n","\n","#test_sentences = T_sentences[ training_samples : LS ]\n","#test_labels = T_labels[training_samples : LS]\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wvZkXTL2Nf_A","executionInfo":{"status":"ok","timestamp":1624526590871,"user_tz":-480,"elapsed":1734,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"b703ea55-503e-4d8a-cf4a-1cf88cc83931"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","# For every sentence...\n","    # `encode` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","\n","# The encode function also supports truncation and conversion to pytorch tensors, \n","# but we need to do padding, so we can't use these features :(\n","                  #max_length = 128,          # Truncate all sentences.\n","                  #return_tensors = 'pt',     # Return pytorch tensors.)\n","for sent in sentences:\n","    encoded_sent = tokenizer.encode(sent, add_special_tokens = True,) # Add '[CLS]' and '[SEP]'\n","    input_ids.append(encoded_sent)\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences[0])\n","print('Token IDs:', input_ids[0])\n","print('Max sentence length: ', max([len(sen) for sen in input_ids]))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Original:  口味：不知道是我口高了，还是这家真不怎么样。 我感觉口味确实很一般很一般。上菜相当快，我敢说菜都是提前做好的。几乎都不热。菜品：酸汤肥牛，干辣干辣的，还有一股泡椒味。着实受不了。。。环境：室内整体装修确实不错，但是大厅人多，太乱。服务：一般吧。说不上好，但是也不差。价格：一般，大众价格，都能接受。人：太多了，排队很厉害。以后不排队也许还会来（比如早去路过），排队就不值了。票据：六日没票！告我周一到周五可能有票~~~ 相当不正规，在这一点同等价位远不如外婆家。\n","Token IDs: [101, 1366, 1456, 8038, 679, 4761, 6887, 3221, 2769, 1366, 7770, 749, 8024, 6820, 3221, 6821, 2157, 4696, 679, 2582, 720, 3416, 511, 2769, 2697, 6230, 1366, 1456, 4802, 2141, 2523, 671, 5663, 2523, 671, 5663, 511, 677, 5831, 4685, 2496, 2571, 8024, 2769, 3140, 6432, 5831, 6963, 3221, 2990, 1184, 976, 1962, 4638, 511, 1126, 725, 6963, 679, 4178, 511, 5831, 1501, 8038, 7000, 3739, 5503, 4281, 8024, 2397, 6793, 2397, 6793, 4638, 8024, 6820, 3300, 671, 5500, 3796, 3492, 1456, 511, 4708, 2141, 1358, 679, 749, 511, 511, 511, 4384, 1862, 8038, 2147, 1079, 3146, 860, 6163, 934, 4802, 2141, 679, 7231, 8024, 852, 3221, 1920, 1324, 782, 1914, 8024, 1922, 744, 511, 3302, 1218, 8038, 671, 5663, 1416, 511, 6432, 679, 677, 1962, 8024, 852, 3221, 738, 679, 2345, 511, 817, 3419, 8038, 671, 5663, 8024, 1920, 830, 817, 3419, 8024, 6963, 5543, 2970, 1358, 511, 782, 8038, 1922, 1914, 749, 8024, 2961, 7339, 2523, 1326, 2154, 511, 809, 1400, 679, 2961, 7339, 738, 6387, 6820, 833, 3341, 8020, 3683, 1963, 3193, 1343, 6662, 6814, 8021, 8024, 2961, 7339, 2218, 679, 966, 749, 511, 4873, 2945, 8038, 1063, 3189, 3766, 4873, 8013, 1440, 2769, 1453, 671, 1168, 1453, 758, 1377, 5543, 3300, 4873, 172, 172, 172, 4685, 2496, 679, 3633, 6226, 8024, 1762, 6821, 671, 4157, 1398, 5023, 817, 855, 6823, 679, 1963, 1912, 2038, 2157, 511, 102]\n","Max sentence length:  925\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nuOxkRyqOFfF","executionInfo":{"status":"ok","timestamp":1624526592525,"user_tz":-480,"elapsed":1656,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"543a6ea8-a270-414d-e917-0f428db47914"},"source":["\n","from keras.preprocessing.sequence import pad_sequences\n","# Set the maximum sequence length.\n","MAX_LEN = 200\n","print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n","print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n","# Pad our input tokens with value 0.\n","# Note ：\"post\" indicates that we want to pad and truncate at the end of the sequence,\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n","                          value=0, truncating=\"post\", padding=\"post\")\n","print('\\Done.')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["\n","Padding/truncating all sentences to 200 values...\n","\n","Padding token: \"[PAD]\", ID: 0\n","\\Done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MA_nA_prNgBU","executionInfo":{"status":"ok","timestamp":1624526592525,"user_tz":-480,"elapsed":4,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}}},"source":["# Create attention masks\n","attention_masks = []\n","# For each sentence...\n","    # Create the attention mask.\n","    #   - If a token ID is 0, then it's padding, set the mask to 0.\n","    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n","for sent in input_ids:\n","    att_mask = [int(token_id > 0) for token_id in sent]\n","    attention_masks.append(att_mask)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZNFFKvC0NgDW","executionInfo":{"status":"ok","timestamp":1624526592938,"user_tz":-480,"elapsed":415,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}}},"source":["# Use train_test_split to split our data into train and validation sets for\n","# training\n","from sklearn.model_selection import train_test_split\n","# Use 90% for training and 10% for validation.\n","train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n","                                                            random_state=2018, test_size=0.1)\n","# Do the same for the masks.\n","train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n","                                             random_state=2018, test_size=0.1)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"8wdPCzLPNgG3","executionInfo":{"status":"ok","timestamp":1624526592939,"user_tz":-480,"elapsed":6,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}}},"source":["# Convert all inputs and labels into torch tensors, the required datatype \n","# for our model.\n","train_inputs = torch.tensor(train_inputs)\n","validation_inputs = torch.tensor(validation_inputs)\n","train_labels = torch.tensor(train_labels)\n","validation_labels = torch.tensor(validation_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_masks = torch.tensor(validation_masks)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qqGjz6djNgH_","executionInfo":{"status":"ok","timestamp":1624526592940,"user_tz":-480,"elapsed":6,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"1db2f900-1583-4980-ce39-b7057219ba22"},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# For fine-tuning BERT on a specific task, the authors recommend a batch size of # 16 or 32.\n","batch_size = 16\n","# Create the DataLoader for our training set.\n","print(train_inputs.size(),train_masks.size(),train_labels.size())\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","# Create the DataLoader for our validation set.\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["torch.Size([1800, 200]) torch.Size([1800, 200]) torch.Size([1800])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uBPWb--wOuen"},"source":["##2.2 train"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8b993d50d46045c9ab588a90502ac374","5ae7f27015244d0ca08b016630807738","b4879e44ec224437927b2504ca63c322","43c89feb256e4da3b30d51116e0e6b5e","0fc86d80fad8449eb890467648b0a2e5","2a37b2869688432981e6fcbbfd69eee5","1731608e6a53496ab1cb1b5aeb0ed3fb","59545af6017945dc99e0f421bdfbfcdc","04074b5d1f2d45999d4347b6da8252ad","bdb60a8577c04a5b8467b3614db06ce3","555142f6bb904231a2cfe4214e83f25f","e5895dc00516429f8e337a806a2cf301","a28e070e4c6f4e9db84fd8a30acdea76","d5948cf9f11d453aa4677cc06dab4255","d19956dad055498b872ab0352ab97497","ffc09015e2f248b5ae99eef70e9c228c"]},"id":"HnFvyMQ_NgKO","executionInfo":{"status":"ok","timestamp":1624526616183,"user_tz":-480,"elapsed":23247,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"0a0b6ba9-af0f-47a2-e612-be76d33da87c"},"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","# Load BertForSequenceClassification, the pretrained BERT model with a single \n","# linear classification layer on top. \n","model = BertForSequenceClassification.from_pretrained(\n","    \"hfl/chinese-bert-wwm-ext\",\n","    num_labels = 2, \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","# \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n"," \n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"execution_count":16,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8b993d50d46045c9ab588a90502ac374","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=647.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04074b5d1f2d45999d4347b6da8252ad","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=411578458.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at hfl/chinese-bert-wwm-ext were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/chinese-bert-wwm-ext and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pZSLJuZDNgNF","executionInfo":{"status":"ok","timestamp":1624526616184,"user_tz":-480,"elapsed":7,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"fbd29539-3866-4023-e188-dd12aff58447"},"source":["# Get all of the model's parameters as a list of tuples.\n","params = list(model.named_parameters())\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","print('==== Embedding Layer ====\\n')\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","print('\\n==== First Transformer ====\\n')\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","print('\\n==== Output Layer ====\\n')\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["The BERT model has 201 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","bert.embeddings.word_embeddings.weight                  (21128, 768)\n","bert.embeddings.position_embeddings.weight                (512, 768)\n","bert.embeddings.token_type_embeddings.weight                (2, 768)\n","bert.embeddings.LayerNorm.weight                              (768,)\n","bert.embeddings.LayerNorm.bias                                (768,)\n","\n","==== First Transformer ====\n","\n","bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.query.bias                (768,)\n","bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n","bert.encoder.layer.0.attention.self.key.bias                  (768,)\n","bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.value.bias                (768,)\n","bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n","bert.encoder.layer.0.attention.output.dense.bias              (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n","bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n","bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n","bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n","bert.encoder.layer.0.output.dense.bias                        (768,)\n","bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n","bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n","\n","==== Output Layer ====\n","\n","bert.pooler.dense.weight                                  (768, 768)\n","bert.pooler.dense.bias                                        (768,)\n","classifier.weight                                           (2, 768)\n","classifier.bias                                                 (2,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-N4vWij4OyLh","executionInfo":{"status":"ok","timestamp":1624526616184,"user_tz":-480,"elapsed":5,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"3d168dc3-8979-4ea5-8b1c-3464008267ff"},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n","# I believe the 'W' stands for 'Weight Decay fix\"\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )\n","from transformers import get_linear_schedule_with_warmup\n","epochs = 4 # Number of training epochs (authors recommend between 2 and 4)\n","# Total number of training steps is number of batches * number of epochs.\n","total_steps = len(train_dataloader) * epochs\n","print(total_steps)\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["452\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1Y1ZMdKFOyTg","executionInfo":{"status":"ok","timestamp":1624526616185,"user_tz":-480,"elapsed":5,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}}},"source":["import numpy as np\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","import time\n","import datetime\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XzaYWNb5Oyjp","executionInfo":{"status":"ok","timestamp":1624526877720,"user_tz":-480,"elapsed":261540,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"62488772-90b6-49d1-d108-e999c9afc44c"},"source":["import random\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","# Store the average loss after each epoch so we can plot them.\n","loss_values = []\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","    # Reset the total loss for this epoch.\n","    total_loss = 0\n","\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train() #just changes the *mode*, it doesn't *perform* the training.\n","    #----------------------- For each batch of training data -----------------------\n","    for step, batch in enumerate(train_dataloader):\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)           \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].long().to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].long().to(device)\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","          # Perform a forward pass (evaluate the model on this training batch).\n","        # This will return the loss (rather than the model output) because we\n","        # have provided the `labels`.\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        outputs = model(b_input_ids, \n","                    token_type_ids=None, \n","                    attention_mask=b_input_mask, \n","                    labels=b_labels)\n","        \n","        # The call to `model` always returns a tuple, so we need to pull the \n","        # loss value out of the tuple.\n","        loss = outputs[0]\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_loss += loss.item()\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","        # Update the learning rate.\n","        scheduler.step()\n","    # Calculate the average loss over the training data.\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","    \n","    # Store the loss value for plotting the learning curve.\n","    loss_values.append(avg_train_loss)\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","    print(\"\")\n","    print(\"Running Validation...\")\n","    t0 = time.time()\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","    # Tracking variables \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        batch = tuple(t.to(device) for t in batch) # Add batch to GPU\n","        b_input_ids, b_input_mask, b_labels = batch # Unpack the inputs from our dataloader\n","        \n","        # Tell the model not to compute or store gradients, saving memory and speeding up validation\n","        with torch.no_grad():        \n","            # Forward pass, calculate logit predictions.\n","            # This will return the logits rather than the loss because we have not provided labels.\n","            # token_type_ids is the same as the \"segment ids\", which differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)\n","        \n","        # Get the \"logits\" output by the model. The \"logits\" are the output\n","        # values prior to applying an activation function like the softmax.\n","        logits = outputs[0]\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # Calculate the accuracy for this batch of test sentences.\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        \n","        # Accumulate the total accuracy.\n","        eval_accuracy += tmp_eval_accuracy\n","        # Track the number of batches\n","        nb_eval_steps += 1\n","    # Report the final accuracy for this validation run.\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","print(\"\")\n","print(\"Training complete!\")"],"execution_count":20,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 4 ========\n","Training...\n","  Batch    40  of    113.    Elapsed: 0:00:21.\n","  Batch    80  of    113.    Elapsed: 0:00:42.\n","\n","  Average training loss: 0.36\n","  Training epcoh took: 0:01:00\n","\n","Running Validation...\n","  Accuracy: 0.89\n","  Validation took: 0:00:02\n","\n","======== Epoch 2 / 4 ========\n","Training...\n","  Batch    40  of    113.    Elapsed: 0:00:22.\n","  Batch    80  of    113.    Elapsed: 0:00:44.\n","\n","  Average training loss: 0.22\n","  Training epcoh took: 0:01:02\n","\n","Running Validation...\n","  Accuracy: 0.88\n","  Validation took: 0:00:03\n","\n","======== Epoch 3 / 4 ========\n","Training...\n","  Batch    40  of    113.    Elapsed: 0:00:23.\n","  Batch    80  of    113.    Elapsed: 0:00:46.\n","\n","  Average training loss: 0.12\n","  Training epcoh took: 0:01:04\n","\n","Running Validation...\n","  Accuracy: 0.88\n","  Validation took: 0:00:03\n","\n","======== Epoch 4 / 4 ========\n","Training...\n","  Batch    40  of    113.    Elapsed: 0:00:23.\n","  Batch    80  of    113.    Elapsed: 0:00:46.\n","\n","  Average training loss: 0.07\n","  Training epcoh took: 0:01:05\n","\n","Running Validation...\n","  Accuracy: 0.89\n","  Validation took: 0:00:03\n","\n","Training complete!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"amcEKdPtOyk0","executionInfo":{"status":"ok","timestamp":1624526880004,"user_tz":-480,"elapsed":2298,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"ddeb8ffe-2566-4383-f134-ff83e6e70ad1"},"source":["import plotly.express as px\n","f = pd.DataFrame(loss_values)\n","f.columns=['Loss']\n","fig = px.line(f, x=f.index, y=f.Loss)\n","fig.update_layout(title='Training loss of the Model',\n","                   xaxis_title='Epoch',\n","                   yaxis_title='Loss')\n","fig.show()"],"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"35ebdcde-5a58-43cf-a1ed-89cbe7a7d619\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"35ebdcde-5a58-43cf-a1ed-89cbe7a7d619\")) {\n","                    Plotly.newPlot(\n","                        '35ebdcde-5a58-43cf-a1ed-89cbe7a7d619',\n","                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"index=%{x}<br>Loss=%{y}\", \"legendgroup\": \"\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0, 1, 2, 3], \"xaxis\": \"x\", \"y\": [0.3645803143097236, 0.2174594137751687, 0.12493488320512121, 0.06826730414532718], \"yaxis\": \"y\"}],\n","                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Training loss of the Model\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Loss\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('35ebdcde-5a58-43cf-a1ed-89cbe7a7d619');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"22BX3sjkQmOl"},"source":["#Part 3 Tesing data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MiV4dkIyZmVI","executionInfo":{"status":"ok","timestamp":1624526960299,"user_tz":-480,"elapsed":270,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"ffbb966a-60dc-47ac-82a9-b0dbd30152dd"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","path =  \"/content/drive/Shareddrives/AI_project/\"\n","df_test = pd.read_csv(path + 'data/1_column_title/simple_label_2kind.csv')\n","test_sentences = df_test['title']\n","test_labels = df_test['label']"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zblkFFhSOyl6","executionInfo":{"status":"ok","timestamp":1624526960561,"user_tz":-480,"elapsed":2,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}}},"source":["import pandas as pd\n","# Load the dataset into a pandas dataframe.\n","'''\n","# Create sentence and label lists\n","sentences = df.sentence.values\n","labels = np.array(df.label.values,dtype=np.int32)\n","'''\n","\n","# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","# For every sentence...\n","for sent in test_sentences:\n","    # `encode` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    encoded_sent = tokenizer.encode(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                   )\n","    \n","    input_ids.append(encoded_sent)\n","# Pad our input tokens\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n","                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n","# Create attention masks\n","attention_masks = []\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  attention_masks.append(seq_mask) \n","# Convert to tensors.\n","prediction_inputs = torch.tensor(input_ids)\n","prediction_masks = torch.tensor(attention_masks)\n","prediction_labels = torch.tensor(test_labels)\n","# Set the batch size.  \n","batch_size = 16  \n","# Create the DataLoader.\n","prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8wLpxELNOym9","executionInfo":{"status":"ok","timestamp":1624526962085,"user_tz":-480,"elapsed":1526,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"dceac5ed-6820-49a5-c8cf-74ae2911aab8"},"source":["# Prediction on test set\n","print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n","# Put model in evaluation mode\n","model.eval()\n","# Tracking variables \n","predictions , true_labels = [], []\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  \n","  # Telling the model not to compute or store gradients, saving memory and \n","  # speeding up prediction\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      outputs = model(b_input_ids, token_type_ids=None, \n","                      attention_mask=b_input_mask)\n","  logits = outputs[0]\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)\n","print('DONE.')\n","print('Positive samples: %d of %d (%.2f%%)' % (test_labels.sum(), len(test_labels), (test_labels.sum() / len(test_labels) * 100.0)))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Predicting labels for 111 test sentences...\n","DONE.\n","Positive samples: 42 of 111 (37.84%)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QfJKu3_IalPA","executionInfo":{"status":"ok","timestamp":1624526962086,"user_tz":-480,"elapsed":9,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"fa3c9911-a684-4037-f40b-e2be1a9a9ed4"},"source":["from sklearn.metrics import matthews_corrcoef\n","matthews_set = []\n","# Evaluate each test batch using Matthew's correlation coefficient\n","print('Calculating Matthews Corr. Coef. for each batch...')\n","# For each input batch...\n","for i in range(len(true_labels)):\n","  \n","  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n","  # and one column for \"1\"). Pick the label with the highest value and turn this\n","  # in to a list of 0s and 1s.\n","  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n","  \n","  # Calculate and store the coef for this batch.  \n","  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n","  matthews_set.append(matthews)\n","  # Combine the predictions for each batch into a single list of 0s and 1s.\n","flat_predictions = [item for sublist in predictions for item in sublist]\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","# Combine the correct labels for each batch into a single list.\n","flat_true_labels = [item for sublist in true_labels for item in sublist]\n","# Calculate the MCC\n","mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n","print('MCC: %.3f' % mcc)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Calculating Matthews Corr. Coef. for each batch...\n","MCC: 0.651\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q_Zbu2moRAsl","executionInfo":{"status":"ok","timestamp":1624526962086,"user_tz":-480,"elapsed":7,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"be8408fe-c713-42c1-80bb-ec6afe7db248"},"source":["count = 0\n","for i in range(len(flat_true_labels)):\n","  if int(flat_predictions[i]) ==  int(flat_true_labels[i]):\n","      count +=1\n","  else:\n","    None\n","    #print(\"title : \",test_sentences[i], flat_true_labels[i],\" wrong label \",flat_predictions[i])\n","print(count, \"正确率： \" ,count/len(flat_true_labels))"],"execution_count":35,"outputs":[{"output_type":"stream","text":["93 正确率：  0.8378378378378378\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aKx8H4YYMNah"},"source":["#Part 4 input news & output their classification"]},{"cell_type":"code","metadata":{"id":"ryGXlluoqM0y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624528779881,"user_tz":-480,"elapsed":2772,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"224b4889-47f4-4e12-9bd1-dcbcf8288b8e"},"source":["!pip install snownlp\n","from snownlp import SnowNLP"],"execution_count":72,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: snownlp in /usr/local/lib/python3.7/dist-packages (0.12.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"h_ib1COmpNCq","executionInfo":{"status":"ok","timestamp":1624528798549,"user_tz":-480,"elapsed":297,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"1a233608-0639-47b6-b149-776b778d73e0"},"source":["media = \"ltn\"\n","catego = '政治'\n","sample_cnt = 200\n","\n","'''\n","udn, storm\n","sector.size :\n","  chinatimes     9129\n","  cna            4060\n","  cts            1052\n","  ebc            1414\n","  ettoday        8469\n","  ltn            8518\n","  media             1\n","  setn           5452\n","  storm          1281 : ['公共政策', '國內'] \n","  udn           11279 : 社會\n","'''"],"execution_count":76,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nudn, storm\\nsector.size :\\n  chinatimes     9129\\n  cna            4060\\n  cts            1052\\n  ebc            1414\\n  ettoday        8469\\n  ltn            8518\\n  media             1\\n  setn           5452\\n  storm          1281 : ['公共政策', '國內'] \\n  udn           11279 : 社會\\n\""]},"metadata":{"tags":[]},"execution_count":76}]},{"cell_type":"markdown","metadata":{"id":"k4LRnsEWdCSO"},"source":["#4.1. output"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fT0AF53MUlIh","executionInfo":{"status":"ok","timestamp":1624528803880,"user_tz":-480,"elapsed":3199,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"4389c21c-a5d8-4c51-9310-c41b06e3c751"},"source":["path =  \"/content/drive/Shareddrives/AI_project/\"\n","df = pd.read_csv(path + 'data/news_all_simplified.csv')\n","df_3col = df[['media', 'category', 'title']]\n","sector = df_3col.groupby('media')\n","sector.size()\n","m = sector.get_group(media) #m=media\n","mc = m.groupby('category') #mc=media category\n","mc_P = mc.get_group(catego)['title'] # mc_P's P means politic\n","data_array = []\n","for line in mc_P[:sample_cnt] : \n","  simple = SnowNLP(line).han #轉簡體\n","  data_array.append(simple)\n","data = pd.DataFrame(data_array, columns = ['title'])\n","#--------------------------------------------------------------\n","\n","# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","# For every sentence...\n","for sent in data_array:\n","    encoded_sent = tokenizer.encode(sent,add_special_tokens = True,)    \n","    input_ids.append(encoded_sent)\n","# Pad our input tokens\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n","                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n","# Create attention masks\n","attention_masks = []\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  attention_masks.append(seq_mask) \n","# Convert to tensors.\n","prediction_inputs = torch.tensor(input_ids)\n","prediction_masks = torch.tensor(attention_masks)\n","prediction_labels = torch.tensor(test_labels)\n","# Set the batch size.  \n","batch_size = 32  \n","# Create the DataLoader.\n","prediction_data = TensorDataset(prediction_inputs, prediction_masks)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n","\n","#--------------------------------------------------------------\n","# Prediction on test set\n","print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n","# Put model in evaluation mode\n","model.eval()\n","# Tracking variables \n","predictions = []\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask = batch\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","  logits = outputs[0]\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  '''label_ids = b_labels.to('cpu').numpy()'''\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  '''true_labels.append(label_ids)'''\n","print('DONE.')\n","#--------------------------------------------------------------\n","matthews_set = []\n","print('Calculating Matthews Corr. Coef. for each batch...')\n","# For each input batch...\n","for i in range(len(predictions)):\n","  \n","  #Pick the label with the highest value and turn this in to a list of 0s and 1s.\n","  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n","  \n","  # Calculate and store the coef for this batch.  \n","  matthews = matthews_corrcoef(pred_labels_i, pred_labels_i)                \n","  matthews_set.append(matthews)\n","\n","flat_predictions = [item for sublist in predictions for item in sublist]\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n"],"execution_count":77,"outputs":[{"output_type":"stream","text":["Predicting labels for 200 test sentences...\n","DONE.\n","Calculating Matthews Corr. Coef. for each batch...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AzW6F9j2V1ae","executionInfo":{"status":"ok","timestamp":1624528805035,"user_tz":-480,"elapsed":1166,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"e76b939f-58e8-405e-9da4-eba2cf0ebaf2"},"source":["pos_idx = []\n","neg_idx  = [] \n","pos_cnt = 0\n","neg_cnt = 0\n","\n","for i in range(len(flat_predictions)):\n","  predict = flat_predictions[i]\n","  if (predict==0) : \n","    neg_cnt+=1\n","    neg_idx.append(i)  \n","  else:\n","    pos_cnt+=1\n","    pos_idx .append(i)\n","#----------------------------------------------------------------\n","# uncomment to output the result as txt & csv files\n","\n","path =  \"/content/drive/Shareddrives/AI_project/\"\n","filepath = path+'result/'+ media +'/'+\"Demo_\"\n","\n","path = filepath+'.txt'\n","f = open(path, 'w')\n","f.write(str(pos_cnt)+\" \")\n","f.close()\n","f = open(path, 'a')\n","f.write(str(neg_cnt))\n","f.close()\n","#----------------------------------------------------------------\n","pos = []\n","neg = [] \n","for idx in pos_idx : pos.append(data_array[idx])\n","for idx in neg_idx : neg.append(data_array[idx])\n","\n","p = pd.DataFrame(pos)\n","p.to_csv(filepath+\"pos.csv\")\n","\n","\n","neg = pd.DataFrame(neg)\n","neg.to_csv(filepath+\"neg.csv\")\n","\n","print(pos_cnt, neg_cnt)"],"execution_count":78,"outputs":[{"output_type":"stream","text":["51 149\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hQNfO85-v8cb"},"source":["# No using"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Juv8tJllMQ5k","executionInfo":{"status":"ok","timestamp":1624047959378,"user_tz":-480,"elapsed":1033695,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"ca258bbf-d4c3-44be-9a1c-f78761f6e3ac"},"source":["path =  \"/content/drive/Shareddrives/AI_project/\"\n","df = pd.read_csv(path + 'data/news_all.csv')\n","df_3col = df[['media', 'category', 'content']]\n","sector = df_3col.groupby('media')\n","#----------------------------------------------------------------\n","for media in [\"中時\",\"中央社\", \"三立\"]:\n","  m = sector.get_group(media) #m=media\n","  mc = m.groupby('category') #mc=media category\n","  mc_P = mc.get_group('政治')['content'] # mc_P's P means politic\n","  data_array = []\n","  for line in mc_P : \n","    simple = SnowNLP(line).han #轉簡體\n","    data_array.append(simple)\n","  data = pd.DataFrame(data_array, columns = ['text'])\n","  data['text'] = data.text.apply(lambda x: \" \".join(jieba.cut(x)))\n","  #----------------------------------------------------------------\n","  tokenizer = Tokenizer(num_words=max_words)\n","  tokenizer.fit_on_texts(data.text)\n","  sequences = tokenizer.texts_to_sequences(data.text)\n","  type(sequences)\n","  data_cnt = (len(sequences))\n","  print(\"data_cnt : \",data_cnt)\n","  #----------------------------------------------------------------\n","  data = pad_sequences(sequences, maxlen=maxlen)\n","  #----------------------------------------------------------------\n","  pos_idx = []\n","  nu_idx  = []\n","  neg_idx  = [] \n","  pos_cnt = 0\n","  nu_cnt = 0\n","  neg_cnt = 0\n","\n","  for i in range(data_cnt):\n","    prediction = model.predict(data[i:i+1])\n","    predict_value = (prediction[0][0])\n","    if (predict_value)<0.3 : \n","      neg_cnt+=1\n","      neg_idx.append(i)\n","    else:\n","      if predict_value>0.6:\n","        pos_cnt+=1\n","        pos_idx .append(i)\n","      else :\n","        nu_cnt+=1\n","        nu_idx .append(i)\n","  #----------------------------------------------------------------\n","  path =  \"/content/drive/Shareddrives/AI_project/\"\n","  filepath = path+'result/'+ media +'/'+\"Demo_\"\n","  print(pos_cnt, nu_cnt, neg_cnt)\n","\n","  path = filepath+'.txt'\n","  f = open(path, 'w')\n","  f.write(str(pos_cnt)+\" \")\n","  f.close()\n","  f = open(path, 'a')\n","  f.write(str(nu_cnt)+\" \")\n","  f.write(str(neg_cnt))\n","  f.close()\n","  #----------------------------------------------------------------\n","  pos = []\n","  nu = []\n","  neg = [] \n","  for idx in pos_idx : pos.append(data_array[idx])\n","  for idx in nu_idx : nu.append(data_array[idx])\n","  for idx in neg_idx : neg.append(data_array[idx])\n","\n","  p = pd.DataFrame(pos)\n","  p.to_csv(filepath+\"pos.csv\")\n","\n","  nu = pd.DataFrame(nu)\n","  nu.to_csv(filepath+\"nu.csv\")\n","\n","  neg = pd.DataFrame(neg)\n","  neg.to_csv(filepath+\"neg.csv\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["data_cnt :  11928\n","3602 5666 2660\n","data_cnt :  3702\n","746 1890 1066\n","data_cnt :  1910\n","294 608 1008\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2X0Gfhh6qLoW"},"source":[""],"execution_count":null,"outputs":[]}]}