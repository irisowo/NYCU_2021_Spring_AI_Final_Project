{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_Bert同類標題.ipynb","provenance":[],"collapsed_sections":["sNhdyYEMKuJP","zyXbAI2Il9mk","22BX3sjkQmOl","hQNfO85-v8cb"]},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"accelerator":"GPU","kernel_info":{"name":"python3"},"language_info":{"name":"python","version":"3.7.0","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"nteract":{"version":"0.12.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a515ad0fd03e4838a0b5245aa4b2c70f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2a208f33ae1d4d37810bac40b3c98202","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fa1e8267a39c43e3a1cfd237798374a3","IPY_MODEL_e6ba922e85654a55b677e2c9150aa864"]}},"2a208f33ae1d4d37810bac40b3c98202":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fa1e8267a39c43e3a1cfd237798374a3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_59bff2b8ad4b42359a598f012a29945e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":109540,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":109540,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eb8b2221005547a3940a07221ba58c2c"}},"e6ba922e85654a55b677e2c9150aa864":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_62488e82cd6f47b6a4711d807f87322f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 110k/110k [00:03&lt;00:00, 33.2kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_813576156e9a4a3183a66179547ed567"}},"59bff2b8ad4b42359a598f012a29945e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"eb8b2221005547a3940a07221ba58c2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"62488e82cd6f47b6a4711d807f87322f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"813576156e9a4a3183a66179547ed567":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f66cfe6d402d472e9546ca8c999f9be6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_aa7abf6e784f499e904f16cc4b492084","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_af0cf80b28af4da591cd959bb2a1a0c7","IPY_MODEL_610ba8987b6747839e98896ae194ee94"]}},"aa7abf6e784f499e904f16cc4b492084":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"af0cf80b28af4da591cd959bb2a1a0c7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_91477f545b21421c9ac7500bd42671a8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_96d37f89ffd5461aa2b8dbe241ea8885"}},"610ba8987b6747839e98896ae194ee94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f072c5bab3174c3e9457ece4ab3052f3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.00/2.00 [00:02&lt;00:00, 1.25s/B]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_32c89bcc685145d09949c92df1f3f48d"}},"91477f545b21421c9ac7500bd42671a8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"96d37f89ffd5461aa2b8dbe241ea8885":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f072c5bab3174c3e9457ece4ab3052f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"32c89bcc685145d09949c92df1f3f48d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6f0ede6d6a3041a395d8605397b08ad3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8e890d7588c84b5bb75378cff6733cf2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_07fb106ca0f94da29c3a539eb13bda89","IPY_MODEL_2da67a0d296547fd9d366083e277a3d9"]}},"8e890d7588c84b5bb75378cff6733cf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"07fb106ca0f94da29c3a539eb13bda89":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0cfcfb8368d54a4a91561b05fa05908e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":112,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":112,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ef0b307fe4a945a689f118959eb500c5"}},"2da67a0d296547fd9d366083e277a3d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fe614542be49419fa7a6c95605c6deb4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 112/112 [00:00&lt;00:00, 146B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fef1af7d54a0484fa7fe9538ebbc8927"}},"0cfcfb8368d54a4a91561b05fa05908e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ef0b307fe4a945a689f118959eb500c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fe614542be49419fa7a6c95605c6deb4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fef1af7d54a0484fa7fe9538ebbc8927":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5696608ccf9e4f17b457fe1da0387da5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b484eefb2e894aee8947efe46d57ac8d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d65f80cdd8a3463a8ad85032be55d890","IPY_MODEL_a1f88145ef0c42aca800d7cd82f8ce09"]}},"b484eefb2e894aee8947efe46d57ac8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d65f80cdd8a3463a8ad85032be55d890":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c3d3aa1e167b481abede93e4212397cd","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":19,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":19,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_521ff3a746d6456aaa14ecc5276626b3"}},"a1f88145ef0c42aca800d7cd82f8ce09":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a003842d2236472aa6f568bb35df89fe","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 19.0/19.0 [00:00&lt;00:00, 19.3B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_448b540905d444b9aa0687688fa1e33b"}},"c3d3aa1e167b481abede93e4212397cd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"521ff3a746d6456aaa14ecc5276626b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a003842d2236472aa6f568bb35df89fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"448b540905d444b9aa0687688fa1e33b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"39754883e2ee4293b0965a3264394e07":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bf30cc1379ce4f529bcfa601e80c80a5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f16d2094d55447e58495ca6e472843e4","IPY_MODEL_fd883aaafbfe45c7bfb91973e9a3db5a"]}},"bf30cc1379ce4f529bcfa601e80c80a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f16d2094d55447e58495ca6e472843e4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1361690a204d4235b61afe8b2bcd3069","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":268961,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":268961,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_69410545be1144a6810ae9467c2d5a5f"}},"fd883aaafbfe45c7bfb91973e9a3db5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_864a2f1f279b48a3b66d1b4fadabb3e3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 269k/269k [00:00&lt;00:00, 1.38MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1adab02581e04f268038a848dd8ad64d"}},"1361690a204d4235b61afe8b2bcd3069":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"69410545be1144a6810ae9467c2d5a5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"864a2f1f279b48a3b66d1b4fadabb3e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1adab02581e04f268038a848dd8ad64d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"76804aac1cd641e681d485d6f0f50db1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_06dbcd7b386347588f22ba630dfa2dc4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_776c7149798648e2ab9d78d3b11d2395","IPY_MODEL_77a953ca156b47d09bc0ff2e460554c1"]}},"06dbcd7b386347588f22ba630dfa2dc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"776c7149798648e2ab9d78d3b11d2395":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5cd217cef84c4b528e83d3fb2783b6ac","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":647,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":647,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c8df9cf7315b49fd8329b0ba3d77e667"}},"77a953ca156b47d09bc0ff2e460554c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_78e2145b0dd04ecc826d9f40b359cfa3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 647/647 [00:13&lt;00:00, 47.3B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_feca3b957d534c0eb8569a884b9e9ddc"}},"5cd217cef84c4b528e83d3fb2783b6ac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c8df9cf7315b49fd8329b0ba3d77e667":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78e2145b0dd04ecc826d9f40b359cfa3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"feca3b957d534c0eb8569a884b9e9ddc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"916c644c9c454696b1b6cbcec5963b98":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c80cafcb300a4e4e85bad558bb92c8e9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d3153ff88aea4cc3a0b38afdc41ddcfd","IPY_MODEL_6e988d26566d484397a50ee5f000a723"]}},"c80cafcb300a4e4e85bad558bb92c8e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d3153ff88aea4cc3a0b38afdc41ddcfd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ddbb2627795344b09e00db3bd8fc6981","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":411578458,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":411578458,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b6a011cbbc4b473889b312a6fad356ca"}},"6e988d26566d484397a50ee5f000a723":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a3158d6d5aa14864863fd0f41a35171d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 412M/412M [00:12&lt;00:00, 32.5MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6ec485cbcbdc4f79a524ed9cd5e565d9"}},"ddbb2627795344b09e00db3bd8fc6981":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b6a011cbbc4b473889b312a6fad356ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a3158d6d5aa14864863fd0f41a35171d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6ec485cbcbdc4f79a524ed9cd5e565d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"sNhdyYEMKuJP"},"source":["# 1. 處理 train data\n","train/test來源 ：https://github.com/wshuyi/demo-chinese-text-classification-lstm-keras/blob/master/demo.ipynb\n","\n","code 來源 ：https://blog.csdn.net/Jerryzhangjy/article/details/110209984"]},{"cell_type":"markdown","metadata":{"id":"muOg73EpM_GG"},"source":["##import"]},{"cell_type":"code","metadata":{"id":"68JkPB8NbKzX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624373749401,"user_tz":-480,"elapsed":4986,"user":{"displayName":"邱彥慈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Givqje8lrID6Vgw0KmKEbuJczqOcD7NshEo0pVJ1Q=s64","userId":"18426713806418194353"}},"outputId":"ff295617-dbc4-4b77-abe5-4e37b6d9c755"},"source":["!pip install keras.utils\n","import pandas as pd\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting keras.utils\n","  Downloading https://files.pythonhosted.org/packages/31/a2/8be2aee1c8cd388e83d447556c2c84a396944c8bad93d710c5e757f8e98e/keras-utils-1.0.13.tar.gz\n","Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.7/dist-packages (from keras.utils) (2.4.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras.utils) (3.13)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras.utils) (1.4.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras.utils) (3.1.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras.utils) (1.19.5)\n","Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->Keras>=2.1.5->keras.utils) (1.5.2)\n","Building wheels for collected packages: keras.utils\n","  Building wheel for keras.utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras.utils: filename=keras_utils-1.0.13-cp37-none-any.whl size=2657 sha256=060291b29c4fb52de28eca967ae39fd07a395c9d6929a8e337fad3376aa66ce4\n","  Stored in directory: /root/.cache/pip/wheels/46/25/27/7707005c1cb27e1ffc8277b004ac295e34767b02b44d73d6be\n","Successfully built keras.utils\n","Installing collected packages: keras.utils\n","Successfully installed keras.utils\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DFRr_P18Mfv2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624373762761,"user_tz":-480,"elapsed":13364,"user":{"displayName":"邱彥慈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Givqje8lrID6Vgw0KmKEbuJczqOcD7NshEo0pVJ1Q=s64","userId":"18426713806418194353"}},"outputId":"6d991118-44e0-4470-cd46-cbdc36673204"},"source":["! pip3 install transformers\n","! pip3 install keras\n","! pip3 install tensorflow"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/92/6153f4912b84ee1ab53ab45663d23e7cf3704161cb5ef18b0c07e207cef2/transformers-4.7.0-py3-none-any.whl (2.5MB)\n","\u001b[K     |████████████████████████████████| 2.5MB 15.2MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting huggingface-hub==0.0.8\n","  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 38.6MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 30.8MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: huggingface-hub, sacremoses, tokenizers, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.7.0\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (3.1.0)\n","Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.5.2)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.5.0)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n","Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n","Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0.dev2021032900)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n","Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.34.1)\n","Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.31.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (2.23.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (57.0.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n","Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow) (4.5.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.5.30)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.4.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q_jYaxZuMrPJ","executionInfo":{"status":"ok","timestamp":1624373767032,"user_tz":-480,"elapsed":4284,"user":{"displayName":"邱彥慈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Givqje8lrID6Vgw0KmKEbuJczqOcD7NshEo0pVJ1Q=s64","userId":"18426713806418194353"}},"outputId":"c1d5f5b0-0ce8-4900-eb6a-8c179be181c7"},"source":["import torch\n","if torch.cuda.is_available():    \n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla K80\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zyXbAI2Il9mk"},"source":["##讀檔"]},{"cell_type":"code","metadata":{"id":"md4Mf2P8CKKb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624373771132,"user_tz":-480,"elapsed":4106,"user":{"displayName":"邱彥慈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Givqje8lrID6Vgw0KmKEbuJczqOcD7NshEo0pVJ1Q=s64","userId":"18426713806418194353"}},"outputId":"73c89b85-bcb6-412d-b5a9-f2f49e6a3e23"},"source":["!git clone https://github.com/wshuyi/demo-chinese-text-classification-lstm-keras.git"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Cloning into 'demo-chinese-text-classification-lstm-keras'...\n","remote: Enumerating objects: 16, done.\u001b[K\n","remote: Total 16 (delta 0), reused 0 (delta 0), pack-reused 16\u001b[K\n","Unpacking objects: 100% (16/16), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qWfsKVfeCZmz","executionInfo":{"status":"ok","timestamp":1624373771133,"user_tz":-480,"elapsed":18,"user":{"displayName":"邱彥慈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Givqje8lrID6Vgw0KmKEbuJczqOcD7NshEo0pVJ1Q=s64","userId":"18426713806418194353"}}},"source":["from pathlib import Path\n","mypath = Path(\"demo-chinese-text-classification-lstm-keras\")"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"ENeThW2vkeEp","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1624373771133,"user_tz":-480,"elapsed":16,"user":{"displayName":"邱彥慈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Givqje8lrID6Vgw0KmKEbuJczqOcD7NshEo0pVJ1Q=s64","userId":"18426713806418194353"}},"outputId":"88e757c5-8b24-4210-f973-61706b6cbf24"},"source":["#-------------Modify the train_path----------------\n","\n","train_path = mypath/'dianping.csv'\n","\n","#-----------------------------------\n","df = pd.read_csv(train_path)\n","df.head(3)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>口味：不知道是我口高了，还是这家真不怎么样。 我感觉口味确实很一般很一般。上菜相当快，我敢说...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>菜品丰富质量好，服务也不错！很喜欢！</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>说真的，不晓得有人排队的理由，香精香精香精香精，拜拜！</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             comment  sentiment\n","0  口味：不知道是我口高了，还是这家真不怎么样。 我感觉口味确实很一般很一般。上菜相当快，我敢说...          0\n","1                                 菜品丰富质量好，服务也不错！很喜欢！          1\n","2                        说真的，不晓得有人排队的理由，香精香精香精香精，拜拜！          0"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"AP6cfTmqNdTX"},"source":["# Bert"]},{"cell_type":"code","metadata":{"id":"12-W8Re7NfwP","executionInfo":{"status":"ok","timestamp":1624373771134,"user_tz":-480,"elapsed":7,"user":{"displayName":"邱彥慈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Givqje8lrID6Vgw0KmKEbuJczqOcD7NshEo0pVJ1Q=s64","userId":"18426713806418194353"}}},"source":["import numpy as np\n","import pandas as pd\n","T_sentences = df.comment.values # T means Total\n","T_labels = np.array(df.sentiment.values,dtype=np.int32)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":274,"referenced_widgets":["a515ad0fd03e4838a0b5245aa4b2c70f","2a208f33ae1d4d37810bac40b3c98202","fa1e8267a39c43e3a1cfd237798374a3","e6ba922e85654a55b677e2c9150aa864","59bff2b8ad4b42359a598f012a29945e","eb8b2221005547a3940a07221ba58c2c","62488e82cd6f47b6a4711d807f87322f","813576156e9a4a3183a66179547ed567","f66cfe6d402d472e9546ca8c999f9be6","aa7abf6e784f499e904f16cc4b492084","af0cf80b28af4da591cd959bb2a1a0c7","610ba8987b6747839e98896ae194ee94","91477f545b21421c9ac7500bd42671a8","96d37f89ffd5461aa2b8dbe241ea8885","f072c5bab3174c3e9457ece4ab3052f3","32c89bcc685145d09949c92df1f3f48d","6f0ede6d6a3041a395d8605397b08ad3","8e890d7588c84b5bb75378cff6733cf2","07fb106ca0f94da29c3a539eb13bda89","2da67a0d296547fd9d366083e277a3d9","0cfcfb8368d54a4a91561b05fa05908e","ef0b307fe4a945a689f118959eb500c5","fe614542be49419fa7a6c95605c6deb4","fef1af7d54a0484fa7fe9538ebbc8927","5696608ccf9e4f17b457fe1da0387da5","b484eefb2e894aee8947efe46d57ac8d","d65f80cdd8a3463a8ad85032be55d890","a1f88145ef0c42aca800d7cd82f8ce09","c3d3aa1e167b481abede93e4212397cd","521ff3a746d6456aaa14ecc5276626b3","a003842d2236472aa6f568bb35df89fe","448b540905d444b9aa0687688fa1e33b","39754883e2ee4293b0965a3264394e07","bf30cc1379ce4f529bcfa601e80c80a5","f16d2094d55447e58495ca6e472843e4","fd883aaafbfe45c7bfb91973e9a3db5a","1361690a204d4235b61afe8b2bcd3069","69410545be1144a6810ae9467c2d5a5f","864a2f1f279b48a3b66d1b4fadabb3e3","1adab02581e04f268038a848dd8ad64d"]},"id":"HJPPN_UvNf6S","executionInfo":{"status":"ok","timestamp":1624373776040,"user_tz":-480,"elapsed":4912,"user":{"displayName":"邱彥慈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Givqje8lrID6Vgw0KmKEbuJczqOcD7NshEo0pVJ1Q=s64","userId":"18426713806418194353"}},"outputId":"64fce3d7-ae04-4532-e6f3-b8f6c0a60bd8"},"source":["from transformers import BertTokenizer\n","from transformers import AutoTokenizer, AutoModelForMaskedLM\n","# Load the BERT tokenizer.\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained(\"hfl/chinese-bert-wwm-ext\")\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Loading BERT tokenizer...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a515ad0fd03e4838a0b5245aa4b2c70f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=109540.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f66cfe6d402d472e9546ca8c999f9be6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f0ede6d6a3041a395d8605397b08ad3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5696608ccf9e4f17b457fe1da0387da5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=19.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"39754883e2ee4293b0965a3264394e07","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=268961.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Q8Lv419xbc5I"},"source":["## training data"]},{"cell_type":"code","metadata":{"id":"_DY3DUcBXhm1","executionInfo":{"status":"ok","timestamp":1624373776041,"user_tz":-480,"elapsed":5,"user":{"displayName":"邱彥慈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Givqje8lrID6Vgw0KmKEbuJczqOcD7NshEo0pVJ1Q=s64","userId":"18426713806418194353"}}},"source":["LS = len(T_sentences)\n","training_samples = (int)(LS * 0.9)\n","sentences = T_sentences #[:training_samples]\n","labels = T_labels #[:training_samples]\n","\n","#test_sentences = T_sentences[ training_samples : LS ]\n","#test_labels = T_labels[training_samples : LS]\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wvZkXTL2Nf_A","executionInfo":{"status":"ok","timestamp":1624373778237,"user_tz":-480,"elapsed":2199,"user":{"displayName":"邱彥慈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Givqje8lrID6Vgw0KmKEbuJczqOcD7NshEo0pVJ1Q=s64","userId":"18426713806418194353"}},"outputId":"8d2adcb0-0277-426c-d633-2361fe1ddbe9"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","# For every sentence...\n","for sent in sentences:\n","    # `encode` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    encoded_sent = tokenizer.encode(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        # This function also supports truncation and conversion\n","                        # to pytorch tensors, but we need to do padding, so we\n","                        # can't use these features :( .\n","                        #max_length = 128,          # Truncate all sentences.\n","                        #return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.\n","    input_ids.append(encoded_sent)\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences[0])\n","print('Token IDs:', input_ids[0])\n","print('Max sentence length: ', max([len(sen) for sen in input_ids]))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Original:  口味：不知道是我口高了，还是这家真不怎么样。 我感觉口味确实很一般很一般。上菜相当快，我敢说菜都是提前做好的。几乎都不热。菜品：酸汤肥牛，干辣干辣的，还有一股泡椒味。着实受不了。。。环境：室内整体装修确实不错，但是大厅人多，太乱。服务：一般吧。说不上好，但是也不差。价格：一般，大众价格，都能接受。人：太多了，排队很厉害。以后不排队也许还会来（比如早去路过），排队就不值了。票据：六日没票！告我周一到周五可能有票~~~ 相当不正规，在这一点同等价位远不如外婆家。\n","Token IDs: [101, 1366, 1456, 8038, 679, 4761, 6887, 3221, 2769, 1366, 7770, 749, 8024, 6820, 3221, 6821, 2157, 4696, 679, 2582, 720, 3416, 511, 2769, 2697, 6230, 1366, 1456, 4802, 2141, 2523, 671, 5663, 2523, 671, 5663, 511, 677, 5831, 4685, 2496, 2571, 8024, 2769, 3140, 6432, 5831, 6963, 3221, 2990, 1184, 976, 1962, 4638, 511, 1126, 725, 6963, 679, 4178, 511, 5831, 1501, 8038, 7000, 3739, 5503, 4281, 8024, 2397, 6793, 2397, 6793, 4638, 8024, 6820, 3300, 671, 5500, 3796, 3492, 1456, 511, 4708, 2141, 1358, 679, 749, 511, 511, 511, 4384, 1862, 8038, 2147, 1079, 3146, 860, 6163, 934, 4802, 2141, 679, 7231, 8024, 852, 3221, 1920, 1324, 782, 1914, 8024, 1922, 744, 511, 3302, 1218, 8038, 671, 5663, 1416, 511, 6432, 679, 677, 1962, 8024, 852, 3221, 738, 679, 2345, 511, 817, 3419, 8038, 671, 5663, 8024, 1920, 830, 817, 3419, 8024, 6963, 5543, 2970, 1358, 511, 782, 8038, 1922, 1914, 749, 8024, 2961, 7339, 2523, 1326, 2154, 511, 809, 1400, 679, 2961, 7339, 738, 6387, 6820, 833, 3341, 8020, 3683, 1963, 3193, 1343, 6662, 6814, 8021, 8024, 2961, 7339, 2218, 679, 966, 749, 511, 4873, 2945, 8038, 1063, 3189, 3766, 4873, 8013, 1440, 2769, 1453, 671, 1168, 1453, 758, 1377, 5543, 3300, 4873, 172, 172, 172, 4685, 2496, 679, 3633, 6226, 8024, 1762, 6821, 671, 4157, 1398, 5023, 817, 855, 6823, 679, 1963, 1912, 2038, 2157, 511, 102]\n","Max sentence length:  925\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nuOxkRyqOFfF","executionInfo":{"status":"ok","timestamp":1624373780115,"user_tz":-480,"elapsed":1890,"user":{"displayName":"邱彥慈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Givqje8lrID6Vgw0KmKEbuJczqOcD7NshEo0pVJ1Q=s64","userId":"18426713806418194353"}},"outputId":"cd935b94-2f58-44d8-8997-8fcd9b92dc63"},"source":["\n","from keras.preprocessing.sequence import pad_sequences\n","# Set the maximum sequence length.\n","MAX_LEN = 200\n","print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n","print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n","# Pad our input tokens with value 0.\n","# 注意 ：\"post\" indicates that we want to pad and truncate at the end of the sequence,\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n","                          value=0, truncating=\"post\", padding=\"post\")\n","print('\\Done.')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["\n","Padding/truncating all sentences to 200 values...\n","\n","Padding token: \"[PAD]\", ID: 0\n","\\Done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MA_nA_prNgBU","executionInfo":{"status":"ok","timestamp":1624373780602,"user_tz":-480,"elapsed":491,"user":{"displayName":"邱彥慈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Givqje8lrID6Vgw0KmKEbuJczqOcD7NshEo0pVJ1Q=s64","userId":"18426713806418194353"}}},"source":["# Create attention masks\n","attention_masks = []\n","# For each sentence...\n","for sent in input_ids:\n","    # Create the attention mask.\n","    #   - If a token ID is 0, then it's padding, set the mask to 0.\n","    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n","    att_mask = [int(token_id > 0) for token_id in sent]\n","    \n","    # Store the attention mask for this sentence.\n","    attention_masks.append(att_mask)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZNFFKvC0NgDW","executionInfo":{"status":"ok","timestamp":1624373780928,"user_tz":-480,"elapsed":329,"user":{"displayName":"邱彥慈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Givqje8lrID6Vgw0KmKEbuJczqOcD7NshEo0pVJ1Q=s64","userId":"18426713806418194353"}}},"source":["# Use train_test_split to split our data into train and validation sets for\n","# training\n","from sklearn.model_selection import train_test_split\n","# Use 90% for training and 10% for validation.\n","train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n","                                                            random_state=2018, test_size=0.1)\n","# Do the same for the masks.\n","train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n","                                             random_state=2018, test_size=0.1)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"8wdPCzLPNgG3","executionInfo":{"status":"ok","timestamp":1624373780929,"user_tz":-480,"elapsed":5,"user":{"displayName":"邱彥慈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Givqje8lrID6Vgw0KmKEbuJczqOcD7NshEo0pVJ1Q=s64","userId":"18426713806418194353"}}},"source":["# Convert all inputs and labels into torch tensors, the required datatype \n","# for our model.\n","train_inputs = torch.tensor(train_inputs)\n","validation_inputs = torch.tensor(validation_inputs)\n","train_labels = torch.tensor(train_labels)\n","validation_labels = torch.tensor(validation_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_masks = torch.tensor(validation_masks)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qqGjz6djNgH_","executionInfo":{"status":"ok","timestamp":1624373780930,"user_tz":-480,"elapsed":5,"user":{"displayName":"邱彥慈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Givqje8lrID6Vgw0KmKEbuJczqOcD7NshEo0pVJ1Q=s64","userId":"18426713806418194353"}},"outputId":"c12742f3-3620-4309-f4b7-bb9034a227a2"},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# For fine-tuning BERT on a specific task, the authors recommend a batch size of # 16 or 32.\n","batch_size = 16\n","# Create the DataLoader for our training set.\n","print(train_inputs.size(),train_masks.size(),train_labels.size())\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","# Create the DataLoader for our validation set.\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["torch.Size([1800, 200]) torch.Size([1800, 200]) torch.Size([1800])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HnFvyMQ_NgKO","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["76804aac1cd641e681d485d6f0f50db1","06dbcd7b386347588f22ba630dfa2dc4","776c7149798648e2ab9d78d3b11d2395","77a953ca156b47d09bc0ff2e460554c1","5cd217cef84c4b528e83d3fb2783b6ac","c8df9cf7315b49fd8329b0ba3d77e667","78e2145b0dd04ecc826d9f40b359cfa3","feca3b957d534c0eb8569a884b9e9ddc","916c644c9c454696b1b6cbcec5963b98","c80cafcb300a4e4e85bad558bb92c8e9","d3153ff88aea4cc3a0b38afdc41ddcfd","6e988d26566d484397a50ee5f000a723","ddbb2627795344b09e00db3bd8fc6981","b6a011cbbc4b473889b312a6fad356ca","a3158d6d5aa14864863fd0f41a35171d","6ec485cbcbdc4f79a524ed9cd5e565d9"]},"executionInfo":{"status":"ok","timestamp":1624373806115,"user_tz":-480,"elapsed":25189,"user":{"displayName":"邱彥慈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Givqje8lrID6Vgw0KmKEbuJczqOcD7NshEo0pVJ1Q=s64","userId":"18426713806418194353"}},"outputId":"0b4ecc4f-0198-4b56-c585-2a9517100af0"},"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","# Load BertForSequenceClassification, the pretrained BERT model with a single \n","# linear classification layer on top. \n","model = BertForSequenceClassification.from_pretrained(\n","    \"hfl/chinese-bert-wwm-ext\",\n","    num_labels = 2, \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","#     \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n"," \n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"execution_count":16,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76804aac1cd641e681d485d6f0f50db1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=647.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"916c644c9c454696b1b6cbcec5963b98","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=411578458.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at hfl/chinese-bert-wwm-ext were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/chinese-bert-wwm-ext and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pZSLJuZDNgNF","executionInfo":{"status":"ok","timestamp":1624373806117,"user_tz":-480,"elapsed":17,"user":{"displayName":"邱彥慈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Givqje8lrID6Vgw0KmKEbuJczqOcD7NshEo0pVJ1Q=s64","userId":"18426713806418194353"}},"outputId":"fa68ac88-cb2d-43b1-83a7-e54f98c4f319"},"source":["# Get all of the model's parameters as a list of tuples.\n","params = list(model.named_parameters())\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","print('==== Embedding Layer ====\\n')\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","print('\\n==== First Transformer ====\\n')\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","print('\\n==== Output Layer ====\\n')\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["The BERT model has 201 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","bert.embeddings.word_embeddings.weight                  (21128, 768)\n","bert.embeddings.position_embeddings.weight                (512, 768)\n","bert.embeddings.token_type_embeddings.weight                (2, 768)\n","bert.embeddings.LayerNorm.weight                              (768,)\n","bert.embeddings.LayerNorm.bias                                (768,)\n","\n","==== First Transformer ====\n","\n","bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.query.bias                (768,)\n","bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n","bert.encoder.layer.0.attention.self.key.bias                  (768,)\n","bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.value.bias                (768,)\n","bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n","bert.encoder.layer.0.attention.output.dense.bias              (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n","bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n","bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n","bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n","bert.encoder.layer.0.output.dense.bias                        (768,)\n","bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n","bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n","\n","==== Output Layer ====\n","\n","bert.pooler.dense.weight                                  (768, 768)\n","bert.pooler.dense.bias                                        (768,)\n","classifier.weight                                           (2, 768)\n","classifier.bias                                                 (2,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-N4vWij4OyLh","executionInfo":{"status":"ok","timestamp":1624373806117,"user_tz":-480,"elapsed":12,"user":{"displayName":"邱彥慈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Givqje8lrID6Vgw0KmKEbuJczqOcD7NshEo0pVJ1Q=s64","userId":"18426713806418194353"}},"outputId":"279e27b0-e2d3-4d89-ddd0-acd5c12cd1be"},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n","# I believe the 'W' stands for 'Weight Decay fix\"\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )\n","from transformers import get_linear_schedule_with_warmup\n","epochs = 4 # Number of training epochs (authors recommend between 2 and 4)\n","# Total number of training steps is number of batches * number of epochs.\n","total_steps = len(train_dataloader) * epochs\n","print(total_steps)\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["452\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1Y1ZMdKFOyTg","executionInfo":{"status":"ok","timestamp":1624373806118,"user_tz":-480,"elapsed":10,"user":{"displayName":"邱彥慈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Givqje8lrID6Vgw0KmKEbuJczqOcD7NshEo0pVJ1Q=s64","userId":"18426713806418194353"}}},"source":["import numpy as np\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","import time\n","import datetime\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XzaYWNb5Oyjp","executionInfo":{"status":"ok","timestamp":1624374287910,"user_tz":-480,"elapsed":481801,"user":{"displayName":"邱彥慈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Givqje8lrID6Vgw0KmKEbuJczqOcD7NshEo0pVJ1Q=s64","userId":"18426713806418194353"}},"outputId":"132cac35-9c6e-49ad-d357-07102a490193"},"source":["import random\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","# Store the average loss after each epoch so we can plot them.\n","loss_values = []\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","    # Reset the total loss for this epoch.\n","    total_loss = 0\n","\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train() #just changes the *mode*, it doesn't *perform* the training.\n","    #----------------------- For each batch of training data -----------------------\n","    for step, batch in enumerate(train_dataloader):\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)           \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        b_input_ids = batch[0].long().to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].long().to(device)\n","\n","        model.zero_grad()        \n","\n","        outputs = model(b_input_ids, \n","                    token_type_ids=None, \n","                    attention_mask=b_input_mask, \n","                    labels=b_labels)\n","\n","        loss = outputs[0]\n","        total_loss += loss.item()\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        optimizer.step()\n","        # Update the learning rate.\n","        scheduler.step()\n","    # Calculate the average loss over the training data.\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","    \n","    # Store the loss value for plotting the learning curve.\n","    loss_values.append(avg_train_loss)\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","    t0 = time.time()\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","    # Tracking variables \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        batch = tuple(t.to(device) for t in batch) # Add batch to GPU\n","        b_input_ids, b_input_mask, b_labels = batch # Unpack the inputs from our dataloader\n","        \n","        # Tell the model not to compute or store gradients, saving memory and speeding up validation\n","        with torch.no_grad():        \n","            outputs = model(b_input_ids, token_type_ids=None,attention_mask=b_input_mask)\n","        \n","        # Get the \"logits\" output by the model. The \"logits\" are the output\n","        # values prior to applying an activation function like the softmax.\n","        logits = outputs[0]\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # Calculate the accuracy for this batch of test sentences.\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        \n","        # Accumulate the total accuracy.\n","        eval_accuracy += tmp_eval_accuracy\n","        # Track the number of batches\n","        nb_eval_steps += 1\n","    # Report the final accuracy for this validation run.\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","print(\"\")\n","print(\"Training complete!\")"],"execution_count":20,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 4 ========\n","Training...\n","  Batch    40  of    113.    Elapsed: 0:00:41.\n","  Batch    80  of    113.    Elapsed: 0:01:22.\n","\n","  Average training loss: 0.36\n","  Training epcoh took: 0:01:56\n","\n","Running Validation...\n","  Accuracy: 0.88\n","  Validation took: 0:00:05\n","\n","======== Epoch 2 / 4 ========\n","Training...\n","  Batch    40  of    113.    Elapsed: 0:00:41.\n","  Batch    80  of    113.    Elapsed: 0:01:22.\n","\n","  Average training loss: 0.24\n","  Training epcoh took: 0:01:56\n","\n","Running Validation...\n","  Accuracy: 0.90\n","  Validation took: 0:00:05\n","\n","======== Epoch 3 / 4 ========\n","Training...\n","  Batch    40  of    113.    Elapsed: 0:00:41.\n","  Batch    80  of    113.    Elapsed: 0:01:23.\n","\n","  Average training loss: 0.13\n","  Training epcoh took: 0:01:56\n","\n","Running Validation...\n","  Accuracy: 0.89\n","  Validation took: 0:00:05\n","\n","======== Epoch 4 / 4 ========\n","Training...\n","  Batch    40  of    113.    Elapsed: 0:00:41.\n","  Batch    80  of    113.    Elapsed: 0:01:22.\n","\n","  Average training loss: 0.07\n","  Training epcoh took: 0:01:55\n","\n","Running Validation...\n","  Accuracy: 0.90\n","  Validation took: 0:00:05\n","\n","Training complete!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"amcEKdPtOyk0","executionInfo":{"status":"ok","timestamp":1624374290107,"user_tz":-480,"elapsed":2220,"user":{"displayName":"邱彥慈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Givqje8lrID6Vgw0KmKEbuJczqOcD7NshEo0pVJ1Q=s64","userId":"18426713806418194353"}},"outputId":"b4508135-2291-4096-f31d-95fc58509623"},"source":["import plotly.express as px\n","f = pd.DataFrame(loss_values)\n","f.columns=['Loss']\n","fig = px.line(f, x=f.index, y=f.Loss)\n","fig.update_layout(title='Training loss of the Model',\n","                   xaxis_title='Epoch',\n","                   yaxis_title='Loss')\n","fig.show()"],"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"da4518e6-d8b8-477c-a896-5cb859712bd0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"da4518e6-d8b8-477c-a896-5cb859712bd0\")) {\n","                    Plotly.newPlot(\n","                        'da4518e6-d8b8-477c-a896-5cb859712bd0',\n","                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"index=%{x}<br>Loss=%{y}\", \"legendgroup\": \"\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0, 1, 2, 3], \"xaxis\": \"x\", \"y\": [0.3607927050144799, 0.2402865793391139, 0.1348355964765744, 0.07456315338479734], \"yaxis\": \"y\"}],\n","                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Training loss of the Model\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Loss\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('da4518e6-d8b8-477c-a896-5cb859712bd0');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"22BX3sjkQmOl"},"source":["## Tesing dataset"]},{"cell_type":"code","metadata":{"id":"MiV4dkIyZmVI"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","path =  \"/content/drive/Shareddrives/AI_project/\"\n","df_test = pd.read_csv(path + 'data/1_column_title/simple_label_2kind.csv')\n","test_sentences = df_test['title']\n","test_labels = df_test['label']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zblkFFhSOyl6"},"source":["import pandas as pd\n","# Load the dataset into a pandas dataframe.\n","'''\n","# Create sentence and label lists\n","sentences = df.sentence.values\n","labels = np.array(df.label.values,dtype=np.int32)\n","'''\n","\n","# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","# For every sentence...\n","for sent in test_sentences:\n","    encoded_sent = tokenizer.encode(sent, add_special_tokens = True, )  \n","    input_ids.append(encoded_sent)\n","\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n","                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n","# Create attention masks\n","attention_masks = []\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  attention_masks.append(seq_mask) \n","\n","# Convert to tensors.\n","prediction_inputs = torch.tensor(input_ids)\n","prediction_masks = torch.tensor(attention_masks)\n","prediction_labels = torch.tensor(test_labels)\n","\n","# Set the batch size.  \n","batch_size = 32  \n","# Create the DataLoader.\n","prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8wLpxELNOym9"},"source":["# Prediction on test set\n","print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n","# Put model in evaluation mode\n","model.eval()\n","# Tracking variables \n","predictions , true_labels = [], []\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  \n","  # Telling the model not to compute or store gradients, saving memory and \n","  # speeding up prediction\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      outputs = model(b_input_ids, token_type_ids=None, \n","                      attention_mask=b_input_mask)\n","  logits = outputs[0]\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)\n","print('DONE.')\n","print('Positive samples: %d of %d (%.2f%%)' % (test_labels.sum(), len(test_labels), (test_labels.sum() / len(test_labels) * 100.0)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QfJKu3_IalPA"},"source":["from sklearn.metrics import matthews_corrcoef\n","matthews_set = []\n","# Evaluate each test batch using Matthew's correlation coefficient\n","print('Calculating Matthews Corr. Coef. for each batch...')\n","# For each input batch...\n","for i in range(len(true_labels)):\n","  \n","  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n","  # and one column for \"1\"). Pick the label with the highest value and turn this\n","  # in to a list of 0s and 1s.\n","  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n","  \n","  # Calculate and store the coef for this batch.  \n","  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n","  matthews_set.append(matthews)\n","  # Combine the predictions for each batch into a single list of 0s and 1s.\n","flat_predictions = [item for sublist in predictions for item in sublist]\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","# Combine the correct labels for each batch into a single list.\n","flat_true_labels = [item for sublist in true_labels for item in sublist]\n","# Calculate the MCC\n","mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n","print('MCC: %.3f' % mcc)\n","\n","#-------------------------------------------------------------------------\n","\n","count = 0\n","for i in range(len(flat_true_labels)):\n","  if int(flat_predictions[i]) ==  int(flat_true_labels[i]):\n","      count +=1\n","  else:\n","    None\n","    #print(\"title : \",test_sentences[i], flat_true_labels[i],\" wrong label \",flat_predictions[i])\n","print(count, \"正确率： \" ,count/len(flat_true_labels))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aKx8H4YYMNah"},"source":["#利用原始Model_output"]},{"cell_type":"code","metadata":{"id":"ryGXlluoqM0y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624363190941,"user_tz":-480,"elapsed":12587,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"5816aba3-7a91-42b5-f60e-5634be02a906"},"source":["!pip install snownlp\n","from snownlp import SnowNLP"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting snownlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/b3/37567686662100d3bce62d3b0f2adec18ab4b9ff2b61abd7a61c39343c1d/snownlp-0.12.3.tar.gz (37.6MB)\n","\u001b[K     |████████████████████████████████| 37.6MB 89kB/s \n","\u001b[?25hBuilding wheels for collected packages: snownlp\n","  Building wheel for snownlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for snownlp: filename=snownlp-0.12.3-cp37-none-any.whl size=37760967 sha256=09fb43c6926693b1e37cb10637dea2f4771a33a8c06f639ae92f58521b073e97\n","  Stored in directory: /root/.cache/pip/wheels/f3/81/25/7c197493bd7daf177016f1a951c5c3a53b1c7e9339fd11ec8f\n","Successfully built snownlp\n","Installing collected packages: snownlp\n","Successfully installed snownlp-0.12.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"h_ib1COmpNCq","executionInfo":{"status":"ok","timestamp":1624363235572,"user_tz":-480,"elapsed":378,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"dbcb76b1-2726-45d2-ed0a-42a9e66ba129"},"source":["media = \"udn\"\n","sample_cnt = 200\n","'''\n","udn, storm\n","sector.size :\n","  chinatimes     9129\n","  cna            4060\n","  cts            1052\n","  ebc            1414\n","  ettoday        8469\n","  ltn            8518\n","  media             1\n","  setn           5452\n","  storm          1281 : ['公共政策', '國內'] \n","  udn           11279 : 社會\n","'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nudn, storm\\nsector.size :\\n  chinatimes     9129\\n  cna            4060\\n  cts            1052\\n  ebc            1414\\n  ettoday        8469\\n  ltn            8518\\n  media             1\\n  setn           5452\\n  storm          1281 : ['公共政策', '國內'] \\n  udn           11279 : 社會\\n\""]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"fT0AF53MUlIh"},"source":["path =  \"/content/drive/Shareddrives/AI_project/\"\n","df = pd.read_csv(path + 'data/a.csv')\n","#df_3col = df[['media', 'category', 'title']]\n","df_3col = df[['media', 'title','point']]\n","#sector = df_3col.groupby('media')\n","#sector.size()\n","#m = sector.get_group(media) #m=media\n","#mc = m.groupby('category') #mc=media category\n","#mc_P = mc.get_group(\"['公共政策', '國內']\")['title'] # mc_P's P means politic\n","mc_P = df_3col['title']\n","\n","data_array = []\n","for line in mc_P : \n","  simple = SnowNLP(line).han #轉簡體\n","  data_array.append(simple)\n","data = pd.DataFrame(data_array, columns = ['title'])\n","#--------------------------------------------------------------\n","\n","# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","# For every sentence...\n","for sent in data_array:\n","    encoded_sent = tokenizer.encode(sent,add_special_tokens = True,)    \n","    input_ids.append(encoded_sent)\n","# Pad our input tokens\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n","                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n","# Create attention masks\n","attention_masks = []\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  attention_masks.append(seq_mask) \n","# Convert to tensors.\n","prediction_inputs = torch.tensor(input_ids)\n","prediction_masks = torch.tensor(attention_masks)\n","prediction_labels = torch.tensor(test_labels)\n","# Set the batch size.  \n","batch_size = 32  \n","# Create the DataLoader.\n","prediction_data = TensorDataset(prediction_inputs, prediction_masks)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n","\n","#--------------------------------------------------------------\n","# Prediction on test set\n","print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n","# Put model in evaluation mode\n","model.eval()\n","# Tracking variables \n","predictions = []\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask = batch\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","  logits = outputs[0]\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  '''label_ids = b_labels.to('cpu').numpy()'''\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  '''true_labels.append(label_ids)'''\n","print('DONE.')\n","#--------------------------------------------------------------\n","matthews_set = []\n","print('Calculating Matthews Corr. Coef. for each batch...')\n","# For each input batch...\n","for i in range(len(predictions)):\n","  \n","  #Pick the label with the highest value and turn this in to a list of 0s and 1s.\n","  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n","  \n","  # Calculate and store the coef for this batch.  \n","  matthews = matthews_corrcoef(pred_labels_i, pred_labels_i)                \n","  matthews_set.append(matthews)\n","\n","flat_predictions = [item for sublist in predictions for item in sublist]\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AzW6F9j2V1ae"},"source":["pos_idx = []\n","neg_idx  = [] \n","pos_cnt = 0\n","neg_cnt = 0\n","\n","for i in range(len(flat_predictions)):\n","  predict = flat_predictions[i]\n","  if (predict==0) : \n","    neg_cnt+=1\n","    neg_idx.append(i)  \n","  else:\n","    pos_cnt+=1\n","    pos_idx .append(i)\n","#----------------------------------------------------------------\n","path =  \"/content/drive/Shareddrives/AI_project/\"\n","filepath = path+'result/a'\n","\n","path = filepath+'.txt'\n","f = open(path, 'w')\n","f.write(str(pos_cnt)+\" \")\n","f.close()\n","f = open(path, 'a')\n","f.write(str(neg_cnt))\n","f.close()\n","#----------------------------------------------------------------\n","pos = []\n","neg = [] \n","for idx in pos_idx : pos.append(data_array[idx])\n","for idx in neg_idx : neg.append(data_array[idx])\n","\n","p = pd.DataFrame(pos)\n","p.to_csv(filepath+\"pos.csv\")\n","\n","\n","neg = pd.DataFrame(neg)\n","neg.to_csv(filepath+\"neg.csv\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uG8XIhnMO-zx"},"source":["pos_u = pos.unique"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DowpIf79oss3","executionInfo":{"status":"ok","timestamp":1624364618296,"user_tz":-480,"elapsed":368,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"edc888f0-ac69-4d89-bbfb-6b827e9cb720"},"source":["print(\"positive cnt : \",pos_cnt,\" negative cnt : \", neg_cnt)\n","print()\n","percentage = (pos_cnt+0.0)/(pos_cnt+neg_cnt)\n","print( \"percentage of positive title\",\"{:.2f}\".format(percentage),\"%\" )\n","\n","nega =  neg[0][10:20]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["positive cnt :  69  negative cnt :  109\n","\n","percentage of positive title 0.39 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AoguukZunlVL"},"source":["neg_unique = []\n","pos_unique = []\n","for idx in pos_idx:\n","  pos_unique.append(str(df_3col.loc[idx]['media'])+\" \"+str(df_3col.loc[idx]['title'])+\" \"+str(df_3col.loc[idx]['point']))\n","\n","for idx in neg_idx:\n","  neg_unique.append(str(df_3col.loc[idx]['media'])+\" \"+str(df_3col.loc[idx]['title'])+\" \"+str(df_3col.loc[idx]['point']))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l3SDMJOot1DJ","executionInfo":{"status":"ok","timestamp":1624365435681,"user_tz":-480,"elapsed":265,"user":{"displayName":"彥慈邱","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDWvPS9k3sBj7236229dtJ82wThwdg0ughTiGlgw=s64","userId":"07202302998826887632"}},"outputId":"efdecaf8-e08d-4c18-c846-a5b09e9b4a32"},"source":["for n in pos_unique:\n","  print(n)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["udn 美赠250万剂疫苗 外交部：展现对台坚定支持与高度重视 1.0\n","cna 美赠250万剂疫苗  吴钊燮：台湾人永远铭记在心 0.9139534235000609\n","chinatimes 美赠250万剂疫苗 萧美琴：加倍的爱启程运往台湾 0.8897879123687744\n","cna 美赠250万剂疫苗将抵台 吴钊燮：台美关系坚若磐石 0.8743146657943726\n","ltn 美国赠台250万剂  张丽善：及时雨解决疫苗荒 0.8694922924041748\n","ltn 美250万剂疫苗今抵台  郑文灿：台美真朋友 0.8530252575874329\n","ltn 白宫：本月完成分配8000万剂疫苗 即刻出货 0.8435049653053284\n","ltn 美赠250万剂莫德纳疫苗 黄敏惠：真的非常感动 0.8361530900001526\n","chinatimes 白宫：未来几天分配完8000万剂疫苗 即刻出货 0.7759473323822021\n","cna 白宫：未来几天分配完8000万剂疫苗 即刻出货 0.7759473323822021\n","udn 白宫：未来几天分配完8000万剂疫苗 即刻出货 0.7759473323822021\n","cts 美赠250万剂疫苗 绿县市首长发文致谢 0.8288391828536987\n","cts 美国加码赠台250万剂疫苗 民进党：非常温暖 0.8181829452514648\n","udn 美赠250万剂疫苗 王定宇：化解中国打压台湾压力 0.8167411088943481\n","cna 美国赠250万剂疫苗 总统：印证台美友好坚若磐石 0.8158669471740723\n","chinatimes 美国加码捐赠250万剂疫苗 行政院：患难之际相助心存感激 0.8149165511131287\n","cna 美捐赠疫苗250万剂 江启臣：印证台美情谊 0.8140252828598022\n","ltn 美国赠我250万剂疫苗 苏贞昌：非常感动  0.8126640915870667\n","cna 美国赠250万剂疫苗 苏贞昌：真的非常感动 0.8124833106994629\n","udn 美国250万剂疫苗将抵台 陈其迈：台美互信互助情谊深厚 0.8016114830970764\n","cna 美捐赠疫苗追加至250万剂 AIT：台湾是可信赖的朋友 0.7900861501693726\n","ltn 美援250万剂莫德纳疫苗明抵台 黄伟哲：真朋友真进展 0.7834275960922241\n","ltn 美赠250万剂疫苗 陈时中郦英杰亲接机 0.7793678045272827\n","cna 赠台疫苗 美国务院：美台人民情谊是关系基础 0.7447797060012817\n","udn 赠台疫苗 美国务院：美台人民情谊是关系基础 0.7447797060012817\n","chinatimes 赠台疫苗 美国务院：美台人民情谊是关系基础 0.7447797060012817\n","cna 赠台疫苗 美国务院：美台人民情谊是关系基础 0.7447797060012817\n","cna 赠台疫苗 美国务院：美台人民情谊是关系基础 0.7447797060012817\n","udn 赠台疫苗 美国务院：美台人民情谊是关系基础 0.7447797060012817\n","chinatimes 赠台疫苗 美国务院：美台人民情谊是关系基础 0.7447797060012817\n","cna 赠台疫苗 美国务院：美台人民情谊是关系基础 0.7447797060012817\n","chinatimes 白宫：未来几天分配完8000万剂疫苗 即刻出货 0.7759473323822021\n","cna 白宫：未来几天分配完8000万剂疫苗 即刻出货 0.7759473323822021\n","udn 白宫：未来几天分配完8000万剂疫苗 即刻出货 0.7759473323822021\n","chinatimes 白宫：未来几天分配完8000万剂疫苗 即刻出货 0.7759473323822021\n","cna 白宫：未来几天分配完8000万剂疫苗 即刻出货 0.7759473323822021\n","udn 白宫：未来几天分配完8000万剂疫苗 即刻出货 0.7759473323822021\n","ltn 美援250万剂莫德纳疫苗 苏紫云：人道承诺、对抗疫苗统战 0.7690291404724121\n","udn 传美捐赠75万剂疫苗明抵台 谢长廷：令人安心的消息 0.7586439847946167\n","cna 美国赠250万剂疫苗 陈时中赞：真朋友、真性情 0.7556365728378296\n","ltn 美250万剂疫苗抵台！ 郑文灿：感谢美国真朋友 0.7494617700576782\n","cna 赠台疫苗 美国务院：美台人民情谊是关系基础 0.7447797060012817\n","udn 赠台疫苗 美国务院：美台人民情谊是关系基础 0.7447797060012817\n","chinatimes 赠台疫苗 美国务院：美台人民情谊是关系基础 0.7447797060012817\n","cna 赠台疫苗 美国务院：美台人民情谊是关系基础 0.7447797060012817\n","cna 赠台疫苗 美国务院：美台人民情谊是关系基础 0.7447797060012817\n","udn 赠台疫苗 美国务院：美台人民情谊是关系基础 0.7447797060012817\n","chinatimes 赠台疫苗 美国务院：美台人民情谊是关系基础 0.7447797060012817\n","cna 赠台疫苗 美国务院：美台人民情谊是关系基础 0.7447797060012817\n","ltn 感谢美国赠台75万剂疫苗花篮涌入 AIT：永远记得台湾的心意 0.7408631443977356\n","chinatimes 缓解疫苗副作用 中医师建议：用中药调养减低不良反应 0.7372446060180664\n","ltn 美国务院发言人发布赠台疫苗讯息 王定宇：代表台美官方互动 0.7370136976242065\n","udn 美国捐赠250万剂疫苗 侯友宜：这情义要永记在心 0.7343420982360841\n","ltn 75万剂疫苗「非常短时间内」交付 美副助卿： 台美正讨论合作生产 0.7321062088012695\n","udn 屏东再获1.64万剂疫苗 潘孟安：疫苗施打安全、有效率 0.7197668552398682\n","cna 美赠疫苗抵台 苏贞昌：向所有工作伙伴致谢 0.7194429636001587\n","chinatimes AZ疫苗到货72.5万剂 苏贞昌：已接种77.5万人次 0.7173848152160645\n","ettoday 美赠250万剂疫苗　AIT：台湾是民主大家庭一份子 0.717124342918396\n","cna 美赠250万剂疫苗 12单位赴AIT高雄分处送花致谢 0.7155891060829163\n","ltn 美赠250万剂疫苗 江启臣︰国际社会听到台湾人民声音 0.7105229496955872\n","chinatimes 美国赠250万剂莫德纳疫苗 黄敏惠：谢谢在台湾最需要时伸出援手 0.7075167894363403\n","cna 日华恳会长：台湾盼300万剂疫苗 日本有的全给了 0.707168459892273\n","cna 日华恳会长：台湾盼300万剂疫苗 日本有的全给了 0.707168459892273\n","cna 日华恳会长：台湾盼300万剂疫苗 日本有的全给了 0.707168459892273\n","cna 日华恳会长：台湾盼300万剂疫苗 日本有的全给了 0.707168459892273\n","udn 援台250万剂莫德纳疫苗清晨起飞 萧美琴到场送机 0.7062022089958191\n","cts 美赠台疫苗大增为250万剂！AIT：明天抵台 0.7055017352104187\n","udn 美赠疫苗抵台 吴钊燮：台湾人民永远铭记这个时刻 0.7038769721984863\n","chinatimes 泰国开始大规模接种疫苗 首批600万剂 0.7021838426589966\n"],"name":"stdout"}]}]}